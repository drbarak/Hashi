{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('ggplot') # prevent border around the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "p = print\n",
    "d = display\n",
    "def val(x):\n",
    "  if (isinstance(x, (int, np.integer)) or isinstance(x, (float, np.float))) and not isinstance(x, (bool, np.bool)):\n",
    "    return x\n",
    "  try:\n",
    "    return int(x) if not x is None else 0\n",
    "  except ValueError:\n",
    "    try:\n",
    "      return float(x)\n",
    "    except ValueError:\n",
    "      return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel - see https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html\n",
    "def to_excel(df):\n",
    "  df.style.\\\n",
    "    to_excel('styled.xlsx', engine='openpyxl')\n",
    "#    applymap(color_negative_red).\\\n",
    "#    apply(highlight_max).\\\n",
    "\n",
    "# see plot_table(hashi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_to_file(df, path, sub_fname=''):\n",
    "  path_ = f'{path}{sub_fname}.png'\n",
    "  page = 0\n",
    "  while page * 28 < len(df):\n",
    "    #p(path_)\n",
    "    df_ = df.iloc[28 * page:28 * (page + 1),]\n",
    "    with open(path_, \"w\") as f:\n",
    "      df_styled = df_.style\n",
    "      dfi.export(df_styled, path_)\n",
    "    os.startfile(path_, \"print\")\n",
    "    page += 1\n",
    "    path_ = f'{path}_{page}{sub_fname}.png'\n",
    "  \n",
    "#disp_to_file(df_sol, fname, '_solution')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPos(df, values):\n",
    "  pos=[]\n",
    "  rows = df.loc[df.isin(values).any(axis=1)].index.to_list()\n",
    "  cols = df.loc[df.isin(values).any(axis=0)].index.to_list()\n",
    "  for r in rows:\n",
    "    for c in cols:\n",
    "      for v in values:\n",
    "        if df.loc[r, c]==v:\n",
    "          pos.append((r, c))\n",
    "  return pos\n",
    "#getPos(hashi, [3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-reproduction",
   "metadata": {},
   "source": [
    "# Get the Hashi Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "consolidated-assault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashi9.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   10  11\n",
       "0    2   0   0   3   0   3   0   3   0   0   1   0\n",
       "1    0   0   0   0   3   0   2   0   0   4   0   2\n",
       "2    0   1   0   3   0   3   0   0   3   0   0   0\n",
       "3    4   0   1   0   2   0   0   1   0   2   0   0\n",
       "4    0   2   0   4   0   0   0   0   4   0   0   4\n",
       "5    0   0   2   0   0   2   0   4   0   2   0   0\n",
       "6    3   0   0   4   0   0   1   0   2   0   0   0\n",
       "7    0   0   3   0   0   1   0   3   0   5   0   2\n",
       "8    0   1   0   2   0   0   2   0   3   0   0   0\n",
       "9    0   0   3   0   0   3   0   2   0   5   0   4\n",
       "10   2   0   0   0   3   0   2   0   1   0   0   0\n",
       "11   0   0   1   0   0   2   0   3   0   3   0   3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: [(0, 0), (1, 6), (1, 11), (3, 4), (3, 9), (4, 1), (5, 2), (5, 5), (5, 9), (6, 8), (7, 11), (8, 3), (8, 6), (9, 7), (10, 0), (10, 6), (11, 5)], 3: [(0, 3), (0, 5), (0, 7), (1, 4), (2, 3), (2, 5), (2, 8), (6, 0), (7, 2), (7, 7), (8, 8), (9, 2), (9, 5), (10, 4), (11, 7), (11, 9), (11, 11)], 4: [(1, 9), (3, 0), (4, 3), (4, 8), (4, 11), (5, 7), (6, 3), (9, 11)], 5: [(7, 9), (9, 9)], 6: [], 7: [], 8: []}\n",
      "Sum =  136\n",
      "Before:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   10  11\n",
       "0    2   0   0   3   0   3   0   3   0   0   1   0\n",
       "1    0   0   0   0   3   0   2   0   0   4   0   2\n",
       "2    0   1   0   3   0   3   0   0   3   0   0   0\n",
       "3    4   0   1   0   2   0   0   1   0   2   0   0\n",
       "4    0   2   0   4   0   0   0   0   4   0   0   4\n",
       "5    0   0   2   0   0   2   0   4   0   2   0   0\n",
       "6    3   0   0   4   0   0   1   0   2   0   0   0\n",
       "7    0   0   3   0   0   1   0   3   0   5   0   2\n",
       "8    0   1   0   2   0   0   2   0   3   0   0   0\n",
       "9    0   0   3   0   0   3   0   2   0   5   0   4\n",
       "10   2   0   0   0   3   0   2   0   1   0   0   0\n",
       "11   0   0   1   0   0   2   0   3   0   3   0   3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum =  136 88\n",
      "Sum =  32 136\n",
      "Sum =  0 32\n",
      "Sum2 =  0\n",
      "Done - ALL CONNECTED\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "fname_ = 'hashi'\n",
    "df_sol = None\n",
    "lists = {}\n",
    "\n",
    "for i in range(9, 10):\n",
    "  fname = f'{fname_}{i}'\n",
    "  f_name = f'{fname}.xlsx'\n",
    "  try:\n",
    "    hashi = pd.read_excel(f_name, header=None)\n",
    "  except:\n",
    "    f_name = f'{fname}.csv'\n",
    "    hashi = pd.read_csv(f_name, header=None)\n",
    "  p(f_name)\n",
    "  hashi.fillna(0, inplace=True)\n",
    "  hashi = hashi.apply(pd.to_numeric, downcast='integer')\n",
    "  rows = len(hashi)\n",
    "  cols = len(hashi.columns)\n",
    "\n",
    "  #plot_table(hashi)\n",
    "  for i in range(2,9):\n",
    "    lists[i] = getPos(hashi, [i])\n",
    "  \n",
    "  solve_hashi()\n",
    "  #disp_to_file(df_sol, fname, '_solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_hashi():\n",
    "  global hashi\n",
    "  hashi[0] = [1,0,4,0,2,0]\n",
    "  hashi[1] = [0,0,0,2,0,3]\n",
    "  hashi[2] = [4,0,7,0,1,0]\n",
    "  hashi[3] = [0,0,0,2,0,5]\n",
    "  hashi[4] = [0,0,3,0,1,0]\n",
    "  hashi[5] = [3,0,0,3,0,3]\n",
    "\n",
    "  hashi = pd.DataFrame(hashi).T\n",
    "  rows = len(hash)\n",
    "  cols = len(hash.columns)\n",
    "\n",
    "  d(hashi)\n",
    "#manual_hashi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-budapest",
   "metadata": {},
   "source": [
    ">### Modify Hashi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-complement",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#hashi.iloc[4,2]='-'\n",
    "#hashi.iloc[5,3]=2\n",
    "#df = hashi\n",
    "#d(df)\n",
    "#df_sol\n",
    "#disp_to_file(df_sol, f_name + '_solution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-messaging",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "nodes = {}\n",
    "roads = {}\n",
    "def make_nodes(hashi):\n",
    "  n = -1\n",
    "  for i in range(rows):\n",
    "    node = None\n",
    "    for j in range(cols):\n",
    "      n += 1\n",
    "      nodes[n] = (i,j)\n",
    "      nodes[(i,j)] = n\n",
    "      if hashi.iloc[i,j] == 0:\n",
    "        continue\n",
    "      if node is None:\n",
    "        node = n\n",
    "        node_val = hashi.iloc[i,j]\n",
    "        continue\n",
    "      if not (node_val == 1 and hashi.iloc[i,j] == 1):\n",
    "        min_ = 2\n",
    "        if (node_val == 2 and hashi.iloc[i,j] == 2):\n",
    "          min_ = 1\n",
    "        roads[node, n] = min(node_val, min(min_, hashi.iloc[i,j]))\n",
    "      node = n\n",
    "      node_val = hashi.iloc[i,j]\n",
    "  # now the columns connections\n",
    "  for j in range(cols):\n",
    "    node = None\n",
    "    for i in range(rows):\n",
    "      n = i * cols + j\n",
    "      if hashi.iloc[i,j] == 0:\n",
    "        continue\n",
    "      if node is None:\n",
    "        node = n\n",
    "        node_val = hashi.iloc[i,j]\n",
    "        continue\n",
    "      if not (node_val == 1 and hashi.iloc[i,j] == 1):\n",
    "        min_ = 2\n",
    "        if (node_val == 2 and hashi.iloc[i,j] == 2):\n",
    "          min_ = 1\n",
    "        roads[node, n] = min(node_val, min(min_, hashi.iloc[i,j]))\n",
    "      node = n\n",
    "      node_val = hashi.iloc[i,j]\n",
    "  if DEBUG:\n",
    "    p('Nodes:', nodes)\n",
    "    p('\\nRoads:\\n')\n",
    "    p(roads)\n",
    "#make_nodes(hashi)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-spectrum",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "links_org = None\n",
    "def make_links():\n",
    "  links = {}\n",
    "  for x, y in roads.keys():\n",
    "      if x in links:\n",
    "          links[x].append(y)\n",
    "      else:\n",
    "          links[x] = [y]\n",
    "      if y in links:\n",
    "          links[y].append(x)\n",
    "      else:\n",
    "          links[y] = [x]\n",
    "  if DEBUG: p(links)\n",
    "  links_org = deepcopy(links)\n",
    "  return links, links_org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-hormone",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-mistress",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_table(df):\n",
    "    if DEBUG: p('In plot_table')\n",
    "    \n",
    "    fig, ax = plt.subplots(dpi=144)\n",
    "    ax.set_facecolor('w')  # white background\n",
    "\n",
    "    df_ = df.T\n",
    "    rows = len(df_)\n",
    "    cols = len(df_.columns)\n",
    "    plt.xlim(-1, rows)\n",
    "    plt.ylim(cols, -1)\n",
    "\n",
    "      # remover borders\n",
    "  #  ax.spines[\"top\"].set_visible(False)\n",
    "  #  ax.spines[\"right\"].set_visible(False)\n",
    "  #  ax.spines[\"left\"].set_visible(False)\n",
    "  #  ax.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "    for i in range(rows):\n",
    "      for j in range(cols):\n",
    "        if val(df_.iloc[i,j]) == 0:\n",
    "          continue\n",
    "        ax.text(i, j, df_.iloc[i, j], \n",
    "           ha=\"center\", va=\"center\",\n",
    "           bbox=dict(boxstyle=\"circle\", facecolor='white', alpha=1, edgecolor='black')\n",
    "           )\n",
    "    png_path = f'{fname}_table.png'\n",
    "    plt.savefig(png_path)\n",
    "    plt.show()\n",
    "\n",
    "    os.startfile(png_path, \"print\")  \n",
    "#plot_table(h_fix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-barcelona",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.transforms as transforms\n",
    "def plot_trip(l):\n",
    "  l_ = {}\n",
    "  if DEBUG: p('in plot_trip', len(l.keys()), l)\n",
    "  fig, ax = plt.subplots(dpi=144)\n",
    "  ax.set_facecolor('w')\n",
    "  plt.xlim(-1, rows)\n",
    "  plt.ylim(cols, -1)\n",
    "\n",
    "  for tup, n_conn in l.items():\n",
    "    new_tup = (tup[1], tup[0])\n",
    "    if new_tup in l_:  # skip duplicates\n",
    "      continue\n",
    "    l_[new_tup] = 0\n",
    "    p1 = nodes[tup[0]]\n",
    "    p2 = nodes[tup[1]]\n",
    "    df = pd.DataFrame([p1, p2], index=['p1', 'p2'])\n",
    "    line, = ax.plot(df[1], df[0], lw=1, color='black')#, lw= 2 * (lw * 2 - 1))\n",
    "\n",
    "    ax.text(p1[1], p1[0], hashi.iloc[p1[0], p1[1]], \n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=dict(boxstyle=\"circle\", facecolor='white', alpha=1, edgecolor='black')\n",
    "         ) \n",
    "    \n",
    "    if n_conn == 1:\n",
    "      continue\n",
    "    # shift the lines over 2 points\n",
    "    # from site: https://matplotlib.org/2.0.2/users/transforms_tutorial.html\n",
    "    dx = df[1][0] - df[1][1]\n",
    "    dy = df[0][0] - df[0][1]\n",
    "    if dx != 0:\n",
    "      dy = 2/72\n",
    "      dx = 0\n",
    "    else:\n",
    "      dy = 0\n",
    "      dx = 2/72\n",
    "    offset = transforms.ScaledTranslation(dx, dy, fig.dpi_scale_trans)\n",
    "    shadow_transform = ax.transData + offset\n",
    "\n",
    "      # now plot the same data with our offset transform;\n",
    "      # use the zorder to make sure we are below the line\n",
    "    ax.plot(df[1], df[0], lw=1, color='black', transform=shadow_transform,  zorder=0.5*line.get_zorder())\n",
    "\n",
    "  png_path = fname + '_plot.png'\n",
    "  plt.savefig(png_path)\n",
    "  plt.show()\n",
    "\n",
    "  os.startfile(png_path, \"print\")  \n",
    "#plot_trip(l)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-confusion",
   "metadata": {},
   "source": [
    "# DO the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-baseball",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.next = None\n",
    "        \n",
    "class Stack:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    " \n",
    "    def push(self, data):\n",
    "        if DEBUG: p('push', data)\n",
    "        if self.head is None:\n",
    "            self.head = Node(data)\n",
    "        else:\n",
    "            new_node = Node(data)\n",
    "            new_node.next = self.head\n",
    "            self.head = new_node\n",
    " \n",
    "    def pop(self):\n",
    "        if self.head is None:\n",
    "            return None\n",
    "        else:\n",
    "            popped = self.head.data\n",
    "            tmp = self.head.next\n",
    "            del self.head\n",
    "            self.head = tmp\n",
    "            if DEBUG: p('pop', popped)\n",
    "            return popped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-enterprise",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "queue = Stack()\n",
    "\n",
    "def find_city(h):\n",
    "       # try a city in the list which has connections left\n",
    "    if DEBUG: p('in find city')\n",
    "    for i in range(rows * cols):\n",
    "      if val(h.iloc[nodes[i]]) > 0:\n",
    "        if DEBUG: p('found city', i)\n",
    "        return i\n",
    "      \n",
    "def is_road_blocked(h, tup, block=['-', '/', 'X']):\n",
    "    node1, node2 = nodes[tup[0]], nodes[tup[1]]\n",
    "    rows=[node1[0], node2[0]]\n",
    "    cols=[node1[1], node2[1]]\n",
    "    if rows[0] > rows[1]:\n",
    "      rows[0], rows[1] = rows[1], rows[0]\n",
    "    if cols[0] > cols[1]:\n",
    "      cols[0], cols[1] = cols[1], cols[0]\n",
    "    for r in range(rows[0], rows[1] + 1):\n",
    "      for c in range(cols[0], cols[1] + 1):\n",
    "#        if (tup[0] == 60 or tup[1] == 60): p('in is_road_blocked', tup, node1, node2, rows, cols, block, r, c, h.iloc[r, c])\n",
    "        if h.iloc[r, c] in block:\n",
    "          return True\n",
    "    return False\n",
    "        \n",
    "def get_next_city(start, l, h, round):\n",
    "  if DEBUG: p(\"start\", start, links[start], l, h.iloc[nodes[start]], 'round=', round)\n",
    "  if DEBUG: d(h)\n",
    "  for city in links[start]:\n",
    "    if DEBUG: p('new city', city, l)\n",
    "      # allow multiple times to connect between cities as long as it is not more than 2 connections\n",
    "      # check if the connection between these 2 cities is already taken care of\n",
    "    tup2 = (city, start)\n",
    "    if tup2 in l:\n",
    "      if DEBUG: p('check',l[tup2], city, start)\n",
    "      if round == 0 or l[tup2] > 1:\n",
    "        continue\n",
    "    tup = (start, city)\n",
    "    if tup in l:\n",
    "      if DEBUG: p('check 2',l[tup], city, start)\n",
    "      if round == 0 or l[tup] > 1:\n",
    "        continue\n",
    "      # check if city has connections left\n",
    "    if DEBUG: p('remain', start, h.iloc[nodes[start]])\n",
    "    if h.iloc[nodes[start]] == 0:\n",
    "      continue  # end of chain, try another city\n",
    "    if DEBUG: p('remain2', city, h.iloc[nodes[city]])\n",
    "    if h.iloc[nodes[city]] == 0:\n",
    "      continue  # can not use this city because no connection left, try another city\n",
    "      # check if there is no block in the middle\n",
    "    if is_road_blocked(h,tup):\n",
    "      if DEBUG: p('blocked')\n",
    "      continue\n",
    "    if not tup in l: \n",
    "      l[tup] = 0\n",
    "    if not tup2 in l: \n",
    "      l[tup2] = 0\n",
    "#    n_conn = roads[(start, city)] if (start, city) in roads else roads[(city, start)]\n",
    "#    l[start][1] = min(h.iloc[nodes[start]], n_conn)  # number of connections\n",
    "    n_conn = 1\n",
    "    l[tup] += n_conn\n",
    "    l[tup2] += n_conn\n",
    "    if l[tup] != l[tup2]:\n",
    "      if DEBUG: p('ERROR: ', tup, tup2, l[tup], l[tup2])\n",
    "      raise Exception\n",
    "#    n_conn = l[start][1]\n",
    "    h.iloc[nodes[start]] -= n_conn # connections left for the cities\n",
    "    h.iloc[nodes[city]] -= n_conn # connections left for the cities\n",
    "    if DEBUG: p(\"city\", city, l)\n",
    "    if DEBUG: d(h)\n",
    "    return city\n",
    "  if DEBUG: p('none')\n",
    "  if round == 1:\n",
    "    return find_city(h)\n",
    "  return None  # end of chain, go back and find a prev city with connections not 0\n",
    "\n",
    "l = {}\n",
    "\n",
    "def trip():\n",
    "  global h_fix\n",
    "  def get_last():\n",
    "    if DEBUG: p('in get_last')\n",
    "    data = queue.pop()\n",
    "    if data is None:  #queue is empty\n",
    "      return None\n",
    "    start = data\n",
    "    lasts.pop()\n",
    "    if DEBUG: p(start)\n",
    "    return start\n",
    "  \n",
    "  def init(start):\n",
    "    if DEBUG: d(h_fix)\n",
    "    h = h_fix.copy()\n",
    "    round = 0\n",
    "    l = l_fix.copy()\n",
    "    while queue.pop():\n",
    "      pass\n",
    "    if start is None:\n",
    "      lasts = []\n",
    "    else:\n",
    "      lasts = [start]\n",
    "      queue.push(start)\n",
    "    return l, h, round, lasts\n",
    "    \n",
    "  n = rows * cols\n",
    "  start = None\n",
    "  if len(links.keys()) > 0:\n",
    "    start = list(links.keys())[0]\n",
    "  l, h, round, lasts = init(start)\n",
    "  while sum_table(h) > 0:\n",
    "    if DEBUG: p(\"lasts\", start, round, lasts)\n",
    "    city = get_next_city(start, l, h, round)\n",
    "    if not city is None:\n",
    "      if city == start:\n",
    "          # no solution so remove the first link  and try another solution\n",
    "        start = list(links.keys())[0]\n",
    "        links[start].pop(0)\n",
    "        if DEBUG: p(\"start again: \", start, links[start])\n",
    "        while get_last() is None:\n",
    "          pass \n",
    "        l, h, round, lasts = init(start)\n",
    "        continue\n",
    "        # is the new city has any connections left\n",
    "      if val(h.iloc[nodes[city]]) > 0:\n",
    "        start = city\n",
    "        queue.push(start)\n",
    "        lasts.append(start)\n",
    "        continue\n",
    "      start = get_last()\n",
    "      if start is None:\n",
    "        start = find_city(h)\n",
    "      continue\n",
    "    start = get_last()\n",
    "    if start == None:\n",
    "      if round > 0:\n",
    "        break\n",
    "      round += 1\n",
    "      start = list(links.keys())[0]\n",
    "  p('finished: ', sum_table(h))\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-control",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "l_fix = None\n",
    "h_fix = None\n",
    "\n",
    "def make_l(l, n1, n2, n_conn):\n",
    "  if n_conn == 0:\n",
    "    return\n",
    "  tup = (n1, n2)\n",
    "  tup2 = (n2, n1)\n",
    "  if not tup in l: \n",
    "    l[tup] = 0\n",
    "  if not tup2 in l: \n",
    "    l[tup2] = 0\n",
    "  l[tup] += n_conn\n",
    "  l[tup2] += n_conn\n",
    "  \n",
    "  rows=[-1,-1]\n",
    "  cols=[-1,-1]\n",
    "  for i in [0, 1]:\n",
    "    node = nodes[tup[i]]\n",
    "    rows[i] = node[0]\n",
    "    cols[i] = node[1]\n",
    "  block = '-'\n",
    "  if rows[0] == rows[1]:\n",
    "    dir = 'right'\n",
    "    if cols[0] > cols[1]:\n",
    "      cols[0], cols[1] = cols[1], cols[0]\n",
    "      dir = 'left'\n",
    "    rows[1] += 1\n",
    "    cols[0] += 1\n",
    "  elif cols[0] == cols[1]:\n",
    "    dir = 'down'\n",
    "    if rows[0] > rows[1]:\n",
    "      rows[0], rows[1] = rows[1], rows[0]\n",
    "      dir = 'up'\n",
    "    cols[1] += 1\n",
    "    rows[0] += 1\n",
    "    block = '/'\n",
    "  for r in range(rows[0], rows[1]):\n",
    "    for c in range(cols[0], cols[1]):\n",
    "      h_fix.iloc[r, c] = block\n",
    "  return dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-label",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def update_link(i, j, node, n_c, lk, reason):\n",
    "  global df_sol\n",
    "\n",
    "  if not n_c is None:\n",
    "    tup_lk = nodes[lk]\n",
    "    n_c = min(n_c, h_fix.iloc[tup_lk])\n",
    "    if n_c <= 0:\n",
    "      return\n",
    "    h_fix.iloc[tup_lk] -= n_c\n",
    "  \n",
    "  new = pd.Series([nodes[node], hashi.iloc[i,j], h_fix.iloc[i,j], n_c, 'remove', h_fix.iloc[i,j], reason], index = df_sol.columns)\n",
    "  if not n_c is None:\n",
    "    new.dir = make_l(l_fix, node, lk, n_c)\n",
    "    h_fix.iloc[i,j] -= n_c\n",
    "    new.new_val = h_fix.iloc[i,j]\n",
    "  df_sol = df_sol.append(new, ignore_index=True)\n",
    "  \n",
    "  if n_c is None:\n",
    "    return\n",
    "    # added 30.03.2021 ( node of 5, connect to node of 3 that was comleted to 2 connections -> node left with 0 (when 3_or_4 was processed, and next the 5_6 was processed and though the node is still on the liks and exception' so now we remocve each node left with 0 and not waitin for the zero cycle))\n",
    "  if h_fix.iloc[i,j] == 0 or h_fix.iloc[tup_lk] == 0 or l_fix[(node, lk)] == 2: \n",
    "    links[lk].remove(node)\n",
    "    if len(links[lk]) == 0:\n",
    "      del links[lk]\n",
    "    links[node].remove(lk)     # added 01.04.2021\n",
    "    if (node in links) and len(links[node]) == 0: #changed on 31.03.2021\n",
    "      del links[node]\n",
    "      \n",
    "def update_links(i, j, node, n_conn, link, reason):\n",
    "  found2 = False\n",
    "  sav_link = deepcopy(link)  # added 02.04.2021 - update_link removes item from the link and thus changes it\n",
    "  for lk in sav_link:\n",
    "    tup = (node, lk)\n",
    "    n_c = n_conn\n",
    "      # check if not already in l_fix\n",
    "    if tup in l_fix: \n",
    "      n_c -= l_fix[tup]\n",
    "    update_link(i, j, node, n_c, lk, reason)\n",
    "      # special case - a city with 1, then the other connections (if the node is 5 or 3 must be 2 connections)\n",
    "    tup_lk = nodes[lk]\n",
    "    if n_conn == 1 and h_fix.iloc[tup_lk] == 0:\n",
    "      found2 = True\n",
    "    elif l_fix[tup] == 2: # if connections = 2 remove the link from the list\n",
    "      if node in links[lk]:\n",
    "        p(links)\n",
    "        p('\\n', i, j, node, lk, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "        links[lk].remove(node)\n",
    "        if len(links[lk]) == 0:\n",
    "          del links[lk]\n",
    "        p('after update_link 0', )\n",
    "  if (node in links) and h_fix.iloc[i,j] == 0:\n",
    "    del links[node]\n",
    "  if found2:\n",
    "    for lk in sav_link:\n",
    "      tup_lk = nodes[lk]\n",
    "      if h_fix.iloc[tup_lk] > 0:\n",
    "        update_link(i, j, node, 1, lk, reason)              \n",
    "              # if connections = 2 remove the link from the list\n",
    "        if node in links[lk]:\n",
    "          d(h_fix)\n",
    "          p(links)\n",
    "          p('\\n', i, j, node, lk, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "          p('after update_link 1')\n",
    "          links[lk].remove(node)\n",
    "          if len(links[lk]) == 0:\n",
    "            del links[lk]\n",
    "      if (node in links) and len(links[node]) == 0:\n",
    "        del links[node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-silver",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fin_cell(found, msg):\n",
    "  if DEBUG: \n",
    "    if found:\n",
    "      d(h_fix)\n",
    "      p(l_fix)\n",
    "      p()\n",
    "      p('links:', links)\n",
    "    else:\n",
    "      p(msg)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-spray",
   "metadata": {},
   "source": [
    "## find 3 or 4 with 2 connections only (usually in a corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_3_or_4(found, i, j, round, subtitle=''):\n",
    "  if val(h_fix.iloc[i, j]) <= 0:\n",
    "    return found\n",
    "  node = nodes[(i,j)]\n",
    "  global DEBUG\n",
    "  #DBG = True if node == 114 else False\n",
    "  link = links_org[node] if round == 0 else links[node]\n",
    "  if len(link) > 2:\n",
    "    return found\n",
    "  if len(link) != 2:  # added 02.04.2021 - if single link or none, no need to process here\n",
    "    return found\n",
    "  do_update = True\n",
    "  reason = f'corner {hashi.iloc[i, j]}'\n",
    "  sav_h =  h_fix.iloc[i,j]\n",
    "  tup0 = nodes[link[0]] \n",
    "  tup1 = nodes[link[1]]  \n",
    "  if round > 0 and len(links_org[node]) > 2:\n",
    "    #if node == 137: p(i, j, node, l_fix, '\\n', links_org[node], link)\n",
    "      # ignore node (3 or 4) that is already connected by 2 connections to another node \n",
    "      # and that is why it is down to 2 nodes left and not due to a block (not really a true corner)\n",
    "    for lk in links_org[node]:\n",
    "        tup = (node, lk)\n",
    "        #if DEBUG or DBG: p('\\t', tup, tup in l_fix)\n",
    "        if tup in l_fix and l_fix[tup] == 2:\n",
    "          #if DEBUG or DBG: p('\\t\\t', tup, l_fix[tup])\n",
    "          return found\n",
    "      # if node is left with 2 links only and has less than 3 connections left it does not qualify as a corner\n",
    "    if len(link) == 2 and h_fix.iloc[i, j] < 2:\n",
    "      return found\n",
    "      # a case where it is not a corner case is when has 2 links, 2 connections left and no link yet between the 2 connections\n",
    "      # unless one of the links has 1 connection left so we need to connect the current node to the other link with 1 connection at least\n",
    "    if len(link) == 2 and h_fix.iloc[i, j] == 2:\n",
    "      found2 = False\n",
    "      for lk in link:\n",
    "        tup = (node, lk)\n",
    "        tup_lk = nodes[lk]\n",
    "        if tup in l_fix:\n",
    "          found2 = True\n",
    "          break\n",
    "        if h_fix.iloc[tup_lk] == 1: #add a connection to the other node\n",
    "          lk = link[1] if lk == link[0] else link[0]\n",
    "          update_link(i, j, node, 1, lk, reason)\n",
    "#          if node == 40: p('call upd0', i, j, node, lk, links[node])\n",
    "          found = found2 = True\n",
    "          do_update = False\n",
    "          break\n",
    "      if not found2:\n",
    "        return found\n",
    "  n_conn = 1 if hashi.iloc[i, j] == 3 or h_fix.iloc[i, j] < 3 else 2  # was < 4, change to < 3 for hashi5\n",
    "  if n_conn == 2 and h_fix.iloc[i, j] == 3 and hashi.iloc[i, j] == 4:\n",
    "    for lk in link:\n",
    "      tup = (node, lk)\n",
    "      tup_lk = nodes[lk]\n",
    "      found2 = False\n",
    "      if tup in l_fix: # found a connection with one of the nodes so it will have no more tan 1 extra connection and the total will not exceed 3\n",
    "        found2 = True\n",
    "        break\n",
    "    if not found2:\n",
    "      n_conn = 1\n",
    "  \n",
    "  if do_update:\n",
    "    update_links(i, j, node, n_conn, links[node], reason)\n",
    "\n",
    "  if sav_h != h_fix.iloc[i,j]:\n",
    "    found = True\n",
    "    if DEBUG or DBG: p('found_3_or_4' + subtitle + ': ', i, j, node, link, tup0, tup1, sav_h, h_fix.iloc[i,j])\n",
    "  return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "attempted-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_3_or_4(round=0):\n",
    "  if round == 0:\n",
    "    find_7_or_8()\n",
    "  found = False\n",
    "  if DEBUG: p()\n",
    "  sub_title = '' if round == 0 else f'_r{round}'\n",
    "  for i, j in lists[3] + lists[4]:\n",
    "    found = process_3_or_4(found, i, j, round, sub_title)\n",
    "#  for i in range(rows):\n",
    "#    for j in range(cols):\n",
    "#      if hashi.iloc[i, j] == 3 or hashi.iloc[i, j] == 4:\n",
    "#          found = process_3_or_4(found, i, j, round, sub_title)\n",
    "  fin_cell(found, 'Not found_3_or_4' + sub_title)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-booking",
   "metadata": {},
   "source": [
    "## find 5 or 6 on the side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_5_or_6(found, i, j, round, subtitle=''):\n",
    "  if val(h_fix.iloc[i, j]) <= 0:\n",
    "    return found\n",
    "  node = nodes[(i,j)]\n",
    "  #DBG = True if node == 54 else False\n",
    "  link = links_org[node] if round == 0 else links[node]\n",
    "  if len(link) > 3:\n",
    "    return found\n",
    "  do_update = True       \n",
    "  sav_h =  h_fix.iloc[i,j]\n",
    "  reason = f'side {hashi.iloc[i, j]}'\n",
    "  tup0 = nodes[link[0]] \n",
    "  tup1 = nodes[link[1]]\n",
    "  tup2 = nodes[link[2]] if len(link) > 2 else None\n",
    "  if round > 0 and len(links_org[node]) > 3:\n",
    "    if len(link) == 3 and h_fix.iloc[i, j] <= 2:\n",
    "      return found\n",
    "#          if DEBUG or DBG: p(i, j, node, h_fix.iloc[i, j], links_org[node], link, l_fix, '\\n')\n",
    "      # if node is left with 2 links only and has more than 2 connections left need to connect 1 for each node (same as 3 in a corner)\n",
    "    if len(link) == 2 and h_fix.iloc[i, j] <= 2:\n",
    "      # ignore node (5 or 6) that is already connected by 2 connections to another node \n",
    "      # and that is why it is down to 2 nodes left and not due to a block (not really a true corner)\n",
    "      # unless one of the links has 1 connection left so we need to connect the current node to the other link with 1 connection at least\n",
    "      if len(link) == 2 and h_fix.iloc[i, j] == 2:  \n",
    "#            found2 = False\n",
    "        #if DEBUG or DBG: p(i, j, node, h_fix.iloc[i, j], links_org[node], link, '\\n', l_fix)\n",
    "          # our node has 2 connections left, and we have 2 nodes in the link\n",
    "          # so we must connect to both with 2, and if we already are connected to both of them, need to complete to 2 connections\n",
    "        count = 0\n",
    "        for lk in link:\n",
    "          tup = (node, lk)\n",
    "          tup_lk = nodes[lk]\n",
    "          if h_fix.iloc[tup_lk] == 1: #add a connection to the other node\n",
    "            lk = link[1] if lk == link[0] else link[0]\n",
    "            update_link(i, j, node, 1, lk, reason)\n",
    "            if DEBUG or DBG: p(i, j, node, link, '\\n', l_fix)\n",
    "            found = found2 = True\n",
    "            do_update = False\n",
    "            break\n",
    "          if tup in l_fix:\n",
    "            count += 1\n",
    "        if count == 2: # need to completet both links to 2 connections\n",
    "          found = found2 = True\n",
    "          do_update = False\n",
    "          update_links(i, j, node, 2, link, reason)\n",
    "      else:\n",
    "        for lk in links_org[node]:\n",
    "          tup = (node, lk)\n",
    "          if DEBUG or DBG: p('\\t', tup, tup in l_fix)\n",
    "          if tup in l_fix and l_fix[tup] == 2:\n",
    "            if DEBUG or DBG: p('\\t\\t', tup, l_fix[tup])\n",
    "            return found\n",
    "    elif len(link) == 3 and len(links_org[node]) == 4 and h_fix.iloc[i, j] < hashi.iloc[i, j]: # added 02.04.2021\n",
    "        # check if went down to 3 nodes due to it's own connections, then it is not really 3 nodes\n",
    "      for lk in links_org[node]:\n",
    "        tup = (node, lk)\n",
    "        if tup in l_fix:\n",
    "          tup_lk = nodes[lk]\n",
    "          if h_fix.iloc[tup_lk] == 0:  # found a node that is 0 and is connected toour node\n",
    "            return found\n",
    "  n_conn = 1 if hashi.iloc[i, j] == 5 else 2\n",
    "  if n_conn == 2 and h_fix.iloc[i, j] == 4 and len(link) == 3:  # added 30.03.2021 (hashi7)\n",
    "    n_conn = 1\n",
    "      # if no connections with any node in the link then need to connect 1 link only to the 2 links that has more than 1\n",
    "    count = 0\n",
    "    for lk in link:\n",
    "      tup = (node, lk)\n",
    "      if tup in l_fix:\n",
    "        count = 1\n",
    "        break\n",
    "    if count == 0:\n",
    "      found = True\n",
    "      do_update = False\n",
    "      for lk in link:\n",
    "        tup = (node, lk)\n",
    "        tup_lk = nodes[lk]\n",
    "        if h_fix.iloc[tup_lk] == 1:\n",
    "          continue\n",
    "        update_link(i, j, node, 1, lk, reason)\n",
    "    \n",
    "  if do_update:\n",
    "    update_links(i, j, node, n_conn, links[node], reason)\n",
    "  if sav_h !=  h_fix.iloc[i,j]:\n",
    "    found = True\n",
    "    if DEBUG: p('found_5_or_6' + subtitle + ': ', i, j, node, link, tup0, tup1, tup2, sav_h, h_fix.iloc[i,j])\n",
    "  return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_5_or_6(round=0):\n",
    "  find_3_or_4(round)\n",
    "  if DEBUG: p()\n",
    "  found = False\n",
    "  \n",
    "  sub_title = '' if round == 0 else f'_r{round}'\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      if hashi.iloc[i, j] == 5 or hashi.iloc[i, j] == 6:\n",
    "          found = process_5_or_6(found, i, j, round, sub_title)\n",
    "\n",
    "  fin_cell(found, 'Not found_5_or_6' + sub_title)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-ethernet",
   "metadata": {},
   "source": [
    "## find 7 or 8 in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_7_or_8():\n",
    "  if DEBUG: p()  \n",
    "  found = False\n",
    "  for i in range(1, rows-1):\n",
    "    for j in range(1, cols-1):\n",
    "      if hashi.iloc[i, j] >= 7:\n",
    "        found = True\n",
    "        node = nodes[(i,j)]\n",
    "        link = links_org[node]\n",
    "        tup0 = nodes[int(link[0])] \n",
    "        tup1 = nodes[int(link[1])] \n",
    "        tup2 = nodes[int(link[2])] \n",
    "        tup3 = nodes[int(link[3])] \n",
    "        if DEBUG: p('found_7_or_8:', i, j, node, link, tup0, tup1, tup2, tup3)\n",
    "        n_conn = 1 if hashi.iloc[i, j] == 7 else 2\n",
    "          # check if not already in l_fix\n",
    "        found2 = False\n",
    "        reason = f'inside {hashi.iloc[i, j]}'\n",
    "        for lk in link:\n",
    "          tup = (node, lk)\n",
    "          n_c = n_conn\n",
    "          if tup in l_fix: \n",
    "            n_c -= l_fix[tup]\n",
    "          update_link(i, j, node, n_c, lk, reason)            \n",
    "            # special case - 7 connected to a city with 1, then the other 2 must be 2 connections\n",
    "          tup_lk = nodes[lk]\n",
    "          if n_conn == 1 and h_fix.iloc[tup_lk] == 0:\n",
    "            found2 = True\n",
    "        if found2:\n",
    "          for lk in link:\n",
    "            tup = (node, lk)\n",
    "            tup_lk = nodes[lk]\n",
    "            if h_fix.iloc[tup_lk] > 0:\n",
    "              update_link(i, j, node, 1, lk, reason)              \n",
    "                    # if connections = 2 remove the link from the list\n",
    "              if node in links[lk]:\n",
    "                p('after update_link 7_8')\n",
    "                links[lk].remove(node)\n",
    "                if len(links[lk]) == 0:\n",
    "                  del links[lk]\n",
    "          if node in links:\n",
    "            del links[node]\n",
    "  fin_cell(found, '\\nNot found_7_or_8\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-evolution",
   "metadata": {},
   "source": [
    "## Special cases: 4 \n",
    "> with 3 neighbours, one of them (or 2) with 1 connection\n",
    "\n",
    "> with 2 neighbours (both must be 2 connections)\n",
    "\n",
    "> 3 neighbours 2 of them nodes of 2 (must have a connection to the 3rd otherwise an island)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_special4(found, h, i, j, round, subtitle=''):\n",
    "  if val(h_fix.iloc[i, j]) <= 0:\n",
    "    return found\n",
    "  node = nodes[(i,j)]\n",
    "  link = links_org[node]\n",
    "  sav_h = h_fix.iloc[i,j]\n",
    "  dbg_key = None\n",
    "  reason = f'special {hashi.iloc[i, j]}'\n",
    "  if len(link) == 3:\n",
    "    tup0 = nodes[int(link[0])] \n",
    "    tup1 = nodes[int(link[1])]\n",
    "    tup2 = nodes[int(link[2])]\n",
    "    if (h.iloc[tup0] == 2 and h.iloc[tup1] == 2) or (h.iloc[tup0] == 2 and h.iloc[tup2] == 2) or (h.iloc[tup2] == 2 and h.iloc[tup1] == 2):\n",
    "      for index in range(3):  # if we have a (4) connected to few nodes, each with 2\n",
    "        if index == 2 and (h.iloc[tup0] == 2 and h.iloc[tup1] == 2):\n",
    "          tup_lk = tup2\n",
    "        elif index == 1 and (h.iloc[tup0] == 2 and h.iloc[tup2] == 2):\n",
    "          tup_lk = tup1\n",
    "        elif index == 0 and (h.iloc[tup1] == 2 and h.iloc[tup2] == 2):\n",
    "          tup_lk = tup0\n",
    "        else:\n",
    "          continue\n",
    "        lk = link[index]\n",
    "        tup = (node, lk)\n",
    "        #p('\\t', i, j, node, link, lk, index, tup, tup in l_fix, h_fix.iloc[tup0], h_fix.iloc[tup1], h_fix.iloc[tup2], h.iloc[tup0], h.iloc[tup1], h.iloc[tup2])\n",
    "        if not tup in l_fix:\n",
    "          update_link(i, j, node, 1, lk, reason + ' island')                \n",
    "          if DEBUG or node == dbg_key: p('found_special4 island' + subtitle + ': ', i, j, node, link, lk, tup_lk, tup, tup in l_fix, \n",
    "                            tup0, tup1, tup2, h_fix.iloc[tup0], h_fix.iloc[tup1], h_fix.iloc[tup2])\n",
    "          found = True\n",
    "    elif h.iloc[tup0] == 1 or h.iloc[tup1] == 1 or h.iloc[tup2] == 1: # check original values\n",
    "      #p('before special4_2', i, j, h_fix.iloc[i,j], link)\n",
    "      #if not DEBUG: d(h_fix)\n",
    "      count = 0\n",
    "      for lk in link:\n",
    "        tup = (node, lk)\n",
    "        tup_lk = nodes[lk]\n",
    "         # check for a node which is 0 and not connected so need to connect the other 2 -> same as 4 with 2 nodes only\n",
    "        #p('\\t', i, j, node, lk, h_fix.iloc[tup_lk], tup in l_fix)\n",
    "        if h_fix.iloc[tup_lk] == 0 and not tup in l_fix:\n",
    "          count = -1\n",
    "          update_links(i, j, node, 2, links[node], reason)\n",
    "          #p('\\tX', i, j, node, lk, h_fix.iloc[tup_lk], tup in l_fix, sav_h, h_fix.iloc[i,j])\n",
    "          found = True\n",
    "          break\n",
    "        if h.iloc[tup_lk] == 1:\n",
    "          count += 1\n",
    "          continue\n",
    "        if tup in l_fix:  # one node with 1 so must be connected to the other 2, but if already connected then we ignore that node\n",
    "          continue\n",
    "        elif h_fix.iloc[tup_lk] > 0:  # found a node which is not 1 and not connected so need to connect\n",
    "          update_link(i, j, node, 1, lk, reason)\n",
    "          if DEBUG or node == dbg_key: p('in special4_2', i, j, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "          # special case of 3 nodes connected to(4) and 2 of them are (1) so the 3rd must have 2 \n",
    "          # connections with our node\n",
    "      if count == 2:\n",
    "        for lk in link:\n",
    "          tup = (node, lk)\n",
    "          tup_lk = nodes[lk]\n",
    "          if h.iloc[tup_lk] == 1:\n",
    "            if tup in l_fix:\n",
    "              continue\n",
    "            if h_fix.iloc[tup_lk] > 0:\n",
    "              update_link(i, j, node, 1, lk, reason)\n",
    "              if DEBUG or node == dbg_key: p('in special4_3', i, j, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "            continue\n",
    "          n_c = 2      # complete to 2 connections\n",
    "            # check if not already in l_fix\n",
    "          if tup in l_fix: \n",
    "            n_c -= l_fix[tup]\n",
    "          if n_c == 0:\n",
    "            continue\n",
    "          update_link(i, j, node, n_c, lk, reason)\n",
    "          if DEBUG or node == dbg_key: p('in special4_4', i, j, n_c, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "      if sav_h != h_fix.iloc[i,j]:\n",
    "        if DEBUG or node == dbg_key: p('found_special4 with 3' + subtitle + ': ', i, j, node, link, h_fix.iloc[i,j], tup0, tup1, tup2, \n",
    "                                       h_fix.iloc[tup0], h_fix.iloc[tup1], h_fix.iloc[tup2], sav_h, h_fix.iloc[i,j])\n",
    "        found = True\n",
    "    elif h_fix.iloc[tup0] == 1 or h_fix.iloc[tup1] == 1 or h_fix.iloc[tup2] == 1: # one node is 1 but not because of a connection to us\n",
    "      if DEBUG or node == dbg_key: p('in special4: C', i, j, node, h_fix.iloc[tup0], h_fix.iloc[tup1], h_fix.iloc[tup2])\n",
    "      count = 0\n",
    "      for lk in link:\n",
    "        tup = (node, lk)\n",
    "        tup_lk = nodes[lk]\n",
    "        if h_fix.iloc[tup_lk] == 1 and not tup in l_fix: # found a node with 1 and not connected to us -> must create a connection to the other 2\n",
    "          count += 1\n",
    "      if count > 0:  # found a node which is 1 and not connected so need to connect the other 2\n",
    "        for lk in link:\n",
    "          tup = (node, lk)\n",
    "          tup_lk = nodes[lk]\n",
    "            # special case of 3 nodes connected to(4) and 2 of them are (1) so the 3rd must have 2 \n",
    "            # connections with our node\n",
    "          if count == 2 and h_fix.iloc[tup_lk] != 1:\n",
    "            n_c = 2      # complete to 2 connections\n",
    "            if tup in l_fix: \n",
    "              n_c -= l_fix[tup]                  \n",
    "            update_link(i, j, node, n_c, lk, reason)\n",
    "          elif count == 1 and not tup in l_fix and h_fix.iloc[tup_lk] > 1:\n",
    "            update_link(i, j, node, 1, lk, reason)\n",
    "      if sav_h != h_fix.iloc[i,j]:\n",
    "        found = True\n",
    "        if DEBUG or node == dbg_key: p('found in special4 node with 1', i, j, lk, count, h_fix.iloc[i,j], h_fix.iloc[tup0], h_fix.iloc[tup1], h_fix.iloc[tup2])\n",
    "  elif len(link) == 2:\n",
    "    for lk in link:\n",
    "      tup = (node, lk) \n",
    "      tup_lk = nodes[lk]\n",
    "      n_c = 2      # complete to 2 connections\n",
    "        # check if not already in l_fix\n",
    "      if tup in l_fix: \n",
    "        n_c -= l_fix[tup]\n",
    "      if n_c == 0:\n",
    "        continue\n",
    "      update_link(i, j, node, n_c, lk, reason)\n",
    "      if DEBUG: p('in special4_5', n_c, i, j, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "    if sav_h != h_fix.iloc[i,j]:\n",
    "      found = True\n",
    "      if DEBUG or node == dbg_key: p('found_special4 with 2' + subtitle + ': ', i, j, node, link, sav_h, h_fix.iloc[i,j])\n",
    "  elif round > 0 and len(links[node]) == 2 and h_fix.iloc[i,j] > 1:  ## added 29.03.2021\n",
    "      # if not connected to any of the links and one of them has 1 connection left we need to connect to the other node\n",
    "      # unless we r left with 1 connection in the node\n",
    "    link = links[node]\n",
    "    count = 0\n",
    "    node1 = None\n",
    "    for lk in link:\n",
    "      tup = (node, lk) \n",
    "      if tup in l_fix:\n",
    "        break\n",
    "      count += 1\n",
    "      tup_lk = nodes[lk]\n",
    "      if h_fix.iloc[tup_lk] == 1:\n",
    "        node1 = lk\n",
    "      #if DEBUG: p('in special4_6A', i, j, node, link, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk], node1)\n",
    "    if count == 2 and not node1 is None:\n",
    "      lk = link[0] if node1 == link[1] else link[1]\n",
    "      tup = (node, lk) \n",
    "      tup_lk = nodes[lk]\n",
    "      update_link(i, j, node, 1, lk, reason)\n",
    "      if DEBUG: p('in special4_6', i, j, node, link, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk], node1)\n",
    "    if sav_h != h_fix.iloc[i,j]:\n",
    "      found = True\n",
    "      if DEBUG or node == dbg_key: p('found_special4 with 2' + subtitle + ': ', i, j, node, link, sav_h, h_fix.iloc[i,j])\n",
    "\n",
    "  return found\n",
    "\n",
    "def find_special4(round=0):\n",
    "  find_5_or_6(round)\n",
    "  if DEBUG: p()\n",
    "  found = False\n",
    "  sub_title = '' if round == 0 else f'_r{round}'\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      if hashi.iloc[i, j] == 4:\n",
    "        found = process_special4(found, hashi, i, j, round)\n",
    "  fin_cell(found, 'Not found_special4' + sub_title)                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-shift",
   "metadata": {},
   "source": [
    "## Special cases 3: \n",
    "> 3 with 2 neighbours, one of them with 1 connection\n",
    "\n",
    "> 2 with 3 nodes of 2,2,1 -> must have a connection with each of the 2 other node otherwise there is an island\n",
    "\n",
    "> 3 with 3 neighbours, 2 of them with 1 connection -> must connect to the 3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_special3(found, h, i, j, round, subtitle=''):\n",
    "  node = nodes[(i,j)]\n",
    "  link = links_org[node] if round == 0 else links_org[node]\n",
    "  sav_h = h_fix.iloc[i,j]\n",
    "  tup0 = nodes[int(link[0])] \n",
    "  tup1 = nodes[int(link[1])]\n",
    "  reason = f'special {hashi.iloc[i, j]}'\n",
    "  if len(link) > 2:\n",
    "    if round == 0 and len(link) == 3 and sav_h == 3:\n",
    "      tup2 = nodes[int(link[2])]\n",
    "      tup_list = [tup0, tup1, tup2]\n",
    "      for tup in tup_list:\n",
    "        if hashi.iloc[tup] == 1:\n",
    "          tup_list.remove(tup)\n",
    "          if hashi.iloc[tup_list[0]] <= 2 and hashi.iloc[tup_list[1]] <= 2:\n",
    "            found = True\n",
    "            for m in [0, 1]:\n",
    "              lk = nodes[tup_list[m]]\n",
    "              update_link(i, j, node, 1, lk, reason)\n",
    "              if DEBUG: p(lk, tup, h_fix.iloc[i,j], tup_list[m], h_fix.iloc[tup_list[m]])\n",
    "          break\n",
    "    elif round > 0 and len(link) == 3 and sav_h == 3:  # check if 2 neighbours with 1 left\n",
    "      tup2 = nodes[int(link[2])]\n",
    "      tup_list = [tup0, tup1, tup2]\n",
    "      sav_list = tup_list.copy()\n",
    "      for tup in tup_list:\n",
    "        if h_fix.iloc[tup] == 1:\n",
    "          sav_list.remove(tup)\n",
    "      if len(sav_list) == 1:\n",
    "        found = True\n",
    "        lk = nodes[sav_list[0]]\n",
    "        update_link(i, j, node, 1, lk, reason)\n",
    "      if found:\n",
    "        if DEBUG: p('found_special3 with 3' + subtitle + ': ', i, j, node, link, tup0, tup1, h.iloc[tup0], h.iloc[tup1], sav_h, h_fix.iloc[i,j])\n",
    "    return found\n",
    "  for lk in link:\n",
    "      tup = (node, lk)\n",
    "      tup_lk = nodes[lk]\n",
    "      if tup in l_fix:\n",
    "        continue\n",
    "      if h_fix.iloc[tup_lk] > 0:\n",
    "          update_link(i, j, node, 1, lk, reason)\n",
    "          if DEBUG: p(1, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "          # special case of 2 nodes connected to(3) and 1 of them is (1) so the 2nd must have 2 \n",
    "          # connections with our node\n",
    "  if h.iloc[tup0] == 1 or h.iloc[tup1] == 1:\n",
    "      for lk in link:\n",
    "          tup = (node, lk)\n",
    "          tup_lk = nodes[lk]\n",
    "          if h.iloc[tup_lk] == 1:\n",
    "            if tup in l_fix:\n",
    "              continue\n",
    "            if h_fix.iloc[tup_lk] > 0:\n",
    "              update_link(i, j, node, 1, lk, reason)\n",
    "              if DEBUG: p(1, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "            continue\n",
    "          n_c = 2      # complete to 2 connections\n",
    "            # check if not already in l_fix\n",
    "          if tup in l_fix: \n",
    "            n_c -= l_fix[tup]\n",
    "          if n_c == 0:\n",
    "            continue\n",
    "          update_link(i, j, node, n_c, lk, reason)\n",
    "          if DEBUG: p(n_c, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "  if sav_h != h_fix.iloc[i,j]:\n",
    "    if DEBUG: p('found_special3 with 2' + subtitle + ': ', i, j, node, link, tup0, tup1, h.iloc[tup0], h.iloc[tup1], sav_h, h_fix.iloc[i,j])\n",
    "    found = True\n",
    "  return found\n",
    "\n",
    "def find_special3(round=0):\n",
    "  find_special4(round)\n",
    "  if DEBUG: p()\n",
    "  found = False\n",
    "  sub_title = '' if round == 0 else f'_r{round}'\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      if hashi.iloc[i, j] == 3:\n",
    "        found = process_special3(found, hashi, i, j, round, sub_title)\n",
    "  fin_cell(found, 'Not found_special3' + sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-soldier",
   "metadata": {},
   "source": [
    "## Special cases: 2 with a neighbour value 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG = False\n",
    "def process_special2(found, i, j, round, subtitle=''):\n",
    "  node = nodes[(i,j)]\n",
    "#        DBG =  True if node == 65 else False\n",
    "  link = links_org[node]\n",
    "  reason = f'special {hashi.iloc[i, j]}'\n",
    "  if len(link) > 2:\n",
    "    if len(link) == 3 and h_fix.iloc[i,j] == 2: # check for an island\n",
    "      tup0 = nodes[int(link[0])] \n",
    "      tup1 = nodes[int(link[1])]\n",
    "      tup2 = nodes[int(link[2])]\n",
    "      h = hashi\n",
    "      if (h.iloc[tup0] == 1 and h.iloc[tup1] == 1) or (h.iloc[tup0] == 1 and h.iloc[tup2] == 1) or (h.iloc[tup2] == 1 and h.iloc[tup1] == 1):\n",
    "        tup_lk = tup0\n",
    "        index = 0\n",
    "        if (h.iloc[tup0] == 1 and h.iloc[tup1] == 1):\n",
    "          tup_lk = tup2\n",
    "          index = 2\n",
    "        elif (h.iloc[tup0] == 1 and h.iloc[tup2] == 1):\n",
    "          tup_lk = tup1\n",
    "          index = 1\n",
    "        lk = link[index]\n",
    "        tup = (node, lk) \n",
    "        if not tup in l_fix:\n",
    "          update_link(i, j, node, 1, lk, reason + ' island')\n",
    "          if DEBUG: p('found_special2 island' + subtitle + ': ', i, j, node, link, lk, tup_lk, tup, tup in l_fix, \n",
    "                            tup0, tup1, tup2, h.iloc[tup0], h.iloc[tup1], h.iloc[tup2])\n",
    "#          if DEBUG or DBG: p('0:', i, j, node, link, h_fix.iloc[i,j])\n",
    "    if round == 0:\n",
    "      return found\n",
    "      # node of 2 with 3+ links originally\n",
    "      # if node value is 1 we leave it for single() to take care of it \n",
    "      # but if here has 2 connections there is nothing more for us to check\n",
    "    if h_fix.iloc[i,j] == 1:\n",
    "      return found\n",
    "  link = links[node]\n",
    "#        if DEBUG or DBG: p('1:', i, j, node, link, h_fix.iloc[i,j])\n",
    "  if len(link) > 2:\n",
    "    return found\n",
    "  if DEBUG or DBG: p(i, j, node, link, h_fix.iloc[i,j])\n",
    "  sav_h = h_fix.iloc[i,j]\n",
    "  tup0 = nodes[int(link[0])] \n",
    "  tup1 = nodes[int(link[1])]\n",
    "  if hashi.iloc[tup0] <= 2 or hashi.iloc[tup1] <= 2:\n",
    "      # special case: node of 2 connected to 2 links, each node of 2 - must connect 1 to each, otherwise -> island\n",
    "    sav_tup = tup0\n",
    "    rounds = 2 if hashi.iloc[tup0] == 2 and hashi.iloc[tup1] == 2 else 1\n",
    "    for _ in range(rounds):\n",
    "#            p('special2', sav_tup, rounds, tup0, i, j, node, link, h_fix.iloc[i,j])\n",
    "      if sav_tup == tup0 and hashi.iloc[tup0] <= 2: # must have a connection with the other node\n",
    "        tup = tup1\n",
    "        index = 1\n",
    "      else:\n",
    "        sav_tup = tup1\n",
    "        tup = tup0\n",
    "        index = 0\n",
    "      lk = link[index]  # link to the node with more than 2\n",
    "      blocked = False\n",
    "      if round > 0: \n",
    "        blocked = is_road_blocked(h_fix, (node, lk))\n",
    "        if blocked and (node, lk) in l_fix:\n",
    "          blocked = False\n",
    "        if DBG: p('blocked:', node, lk, blocked, (node, lk) in l_fix)\n",
    "        if not blocked:  # check if the 2nd link is blocked\n",
    "          index_ = 1 - index\n",
    "          lk_ = link[index_]\n",
    "          blocked = is_road_blocked(h_fix, (node, lk_))\n",
    "            # check for soft block\n",
    "          if blocked and (node, lk_) in l_fix:\n",
    "            blocked = False\n",
    "          if DBG: p('blocked2:', node, lk_, blocked, (node, lk_) in l_fix)\n",
    "          if False and blocked:\n",
    "            index = index_\n",
    "            lk = lk_\n",
    "      if not blocked and (node, lk) in l_fix and sav_h == h_fix.iloc[i,j]:\n",
    "        return found\n",
    "        # if 2 links and one is blocked then set node to 0\n",
    "      n_c = 1\n",
    "      if blocked and len(link) == 2:\n",
    "        n_c = h_fix.iloc[i,j]\n",
    "      update_link(i, j, node, n_c, lk, reason)            \n",
    "      if DEBUG or DBG: p(n_c, i, j, node, link, lk, h_fix.iloc[i,j], sav_h, tup, tup0, h_fix.iloc[tup0], tup1, h_fix.iloc[tup1])\n",
    "      if h_fix.iloc[i,j] == 0:\n",
    "        for lk in links_org[node]:\n",
    "          if not lk in links:\n",
    "            continue\n",
    "          if not node in links[lk]:\n",
    "            continue\n",
    "          if DEBUG or DBG: p('remove', node, lk)\n",
    "          links[lk].remove(node)\n",
    "          if len(links[lk]) == 0:\n",
    "            del links[lk]\n",
    "        del links[node]\n",
    "        if rounds == 2:\n",
    "          break\n",
    "      else:\n",
    "#              p('special2_0', sav_tup, rounds, tup0, i, j, node, link, h_fix.iloc[i,j])\n",
    "        if sav_tup == tup1:\n",
    "          break\n",
    "        sav_tup = tup1\n",
    "#              p('special2_1', sav_tup, rounds, tup, tup0, tup1, i, j, node, link, h_fix.iloc[i,j])\n",
    "  elif h_fix.iloc[tup0] == 1 or h_fix.iloc[tup1] == 1:\n",
    "      # special case: node of 2 connected to 2 links, one node of 1 - must connect 1 to the other\n",
    "      # unless already connected to any of them\n",
    "      if not (node, link[0]) in l_fix and not (node, link[1]) in l_fix:\n",
    "        if h_fix.iloc[tup0] == 1: # must have a connection with the other node (unless connected already toit and this one of the causes there is 1 connection left)\n",
    "          tup = tup1\n",
    "          index = 1\n",
    "        else:\n",
    "          tup = tup0\n",
    "          index = 0\n",
    "        lk = link[index]  # link to the other node\n",
    "        if not (node, lk) in l_fix:\n",
    "          update_link(i, j, node, 1, lk, reason)            \n",
    "\n",
    "  if sav_h != h_fix.iloc[i,j]:\n",
    "    if DEBUG or DBG: p('found_special2 with 2' + subtitle + ': ', i, j, node, link, h_fix.iloc[i,j], \n",
    "                       tup0, tup1, h_fix.iloc[tup0], h_fix.iloc[tup1], sav_h, h_fix.iloc[i,j])\n",
    "    found = True\n",
    "    if DBG: p(l_fix)\n",
    "  return found\n",
    "\n",
    "def find_special2(round=0):\n",
    "  find_special3(round)\n",
    "  if DEBUG: p()\n",
    "  found = False\n",
    "  sub_title = '' if round == 0 else f'_r{round}'\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      if hashi.iloc[i, j] == 2 and val(h_fix.iloc[i, j]) > 0:\n",
    "        found = process_special2(found, i, j, round)\n",
    "  fin_cell(found, 'Not found_special2' + sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-letters",
   "metadata": {},
   "source": [
    "## Special cases: 6 with 4 neighbours, one of them (or 2) with 1 connection, or with 3 neighbours (all must be 2 connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_special6(round=0):\n",
    "  find_special2(round)\n",
    "  if DEBUG: p()\n",
    "  found = False\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      if hashi.iloc[i, j] == 6:\n",
    "        reason = f'special {hashi.iloc[i, j]}'\n",
    "        node = nodes[(i,j)]\n",
    "        link = links_org[node]\n",
    "        if len(link) == 4:\n",
    "          tup0 = nodes[int(link[0])] \n",
    "          tup1 = nodes[int(link[1])] \n",
    "          tup2 = nodes[int(link[2])]\n",
    "          tup3 = nodes[int(link[3])]\n",
    "          if hashi.iloc[tup0] == 1 or hashi.iloc[tup1] == 1 or hashi.iloc[tup2] == 1 or hashi.iloc[tup3] == 1:\n",
    "            if DEBUG: p('found_special6 with 4:', i, j, node, link, tup0, tup1, tup2, tup3, \n",
    "                  hashi.iloc[tup0], hashi.iloc[tup1], hashi.iloc[tup2], hashi.iloc[tup3])\n",
    "            found = True\n",
    "            count = 0\n",
    "            for lk in link:\n",
    "              tup = (node, lk)\n",
    "              tup_lk = nodes[lk]\n",
    "              if hashi.iloc[tup_lk] == 1:\n",
    "                count += 1\n",
    "                continue\n",
    "              if tup in l_fix:\n",
    "                continue\n",
    "              if h_fix.iloc[tup_lk] > 0:\n",
    "                update_link(i, j, node, 1, lk, reason)                \n",
    "                if DEBUG: p(1, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "                # special case of 4 nodes connected to(6) and 2 of them are (1) so the 3rd and 4th must have 2 \n",
    "                # connections with our node\n",
    "            if count == 2:\n",
    "              for lk in link:\n",
    "                tup = (node, lk)\n",
    "                tup_lk = nodes[lk]\n",
    "                if hashi.iloc[tup_lk] == 1:\n",
    "                  if tup in l_fix:\n",
    "                    continue\n",
    "                  if h_fix.iloc[tup_lk] > 0:\n",
    "                    update_link(i, j, node, n_c, lk, reason)\n",
    "                    if DEBUG: p(1, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "                  continue\n",
    "                n_c = 2      # complete to 2 connections\n",
    "                  # check if not already in l_fix\n",
    "                if tup in l_fix: \n",
    "                  n_c -= l_fix[tup]\n",
    "                if n_c == 0:\n",
    "                  continue\n",
    "                update_link(i, j, node, n_c, lk, reason)\n",
    "                if DEBUG: p(n_c, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "        elif len(link) == 3:\n",
    "          found = True\n",
    "          if DEBUG: p('found_special6 with 3:', i, j, node, link)\n",
    "          for lk in link:\n",
    "            tup = (node, lk)\n",
    "            tup_lk = nodes[lk]\n",
    "            n_c = 2      # complete to 2 connections\n",
    "              # check if not already in l_fix\n",
    "            if tup in l_fix: \n",
    "              n_c -= l_fix[tup]\n",
    "            if n_c == 0:\n",
    "              continue\n",
    "            update_link(i, j, node, n_c, lk, reason)\n",
    "            if DEBUG: p(n_c, lk, tup, h_fix.iloc[i,j], tup_lk, h_fix.iloc[tup_lk])\n",
    "  fin_cell(found, 'Not found_special6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-jacob",
   "metadata": {},
   "source": [
    "## remove links from cities with 0 connections left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_connections(round=0):\n",
    "  if round >= 0:\n",
    "    find_special6(round)\n",
    "    if DEBUG: p()\n",
    "  found = False\n",
    "  for city in list(links.keys()):\n",
    "    node = nodes[city]\n",
    "    if h_fix.iloc[node] == 0:\n",
    "      if not city in links:\n",
    "        continue\n",
    "      if DEBUG: p('found_remove_zero:',city, node, h_fix.iloc[node], links[city])\n",
    "      found = True\n",
    "      for c in links[city]:\n",
    "        if not c in links:  # already removed\n",
    "          continue\n",
    "        link = links[c]\n",
    "        if city in link:\n",
    "          link.remove(city)\n",
    "          if DEBUG: p('\\t', c, link)\n",
    "        links[c] = link\n",
    "        if len(link) == 0:\n",
    "          del links[c]\n",
    "      del links[city]\n",
    "        # because links[] is modified we need to restart the loop\n",
    "      remove_zero_connections(round=-1)\n",
    "  if not DEBUG: return found\n",
    "  if round == 0:\n",
    "    fin_cell(found, 'Not found_remove_zero')\n",
    "  return found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-enemy",
   "metadata": {},
   "source": [
    "## Remove single connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single(round=0):\n",
    "  if round >= 0:\n",
    "    remove_zero_connections(round)\n",
    "    if DEBUG: p()\n",
    "  found = False\n",
    "  if DEBUG:\n",
    "    p('links', links)\n",
    "    p()\n",
    "    p(list(links.keys()))\n",
    "    p()\n",
    "  for city in list(links.keys()):\n",
    "    if len(links[city]) == 1:\n",
    "      node1 = nodes[city]\n",
    "      c = links[city][0]\n",
    "      node2 = nodes[c]\n",
    "      if DEBUG: p('found single:', city, links[city], links[c], node1, h_fix.iloc[node1], node2, h_fix.iloc[node2])\n",
    "      found = True\n",
    "      reason = f'single {hashi.iloc[node1]}'\n",
    "      n_c = h_fix.iloc[node1]\n",
    "      if n_c > 0:\n",
    "#        make_l(l_fix, city, c, n_c)\n",
    "#        h_fix.iloc[node2] -= n_c\n",
    "#        h_fix.iloc[node1] -= n_c\n",
    "        update_link(node1[0], node1[1], city, n_c, c, reason)        \n",
    "        if DEBUG: d(h_fix)\n",
    "      else:\n",
    "        p('in remove single: after update link')\n",
    "        link = links[c]\n",
    "        link.remove(city)\n",
    "        del links[city]\n",
    "        if len(link) == 0:\n",
    "          del links[c]\n",
    "      if h_fix.iloc[node1] == 0 or h_fix.iloc[node2] == 0: \n",
    "        remove_zero_connections(round=-1)\n",
    "      if DEBUG: p(l_fix)\n",
    "        # because links[] is modified we need to restart the loop\n",
    "      return remove_single(round=-1)\n",
    "  if not DEBUG: return found\n",
    "  if round == 0:\n",
    "    fin_cell(found, 'Not found_single')\n",
    "  return found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-gambling",
   "metadata": {},
   "source": [
    "## Prepare blocked table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG = False\n",
    "def prepare_blocked_table(round=0):\n",
    "  global l_fix, h_fix, DEBUG\n",
    "  if len(links) == 0:  # doing a 'test' and no more links -> need another test\n",
    "    #DEBUG = True\n",
    "    return\n",
    "  if round >= 0:\n",
    "    remove_single(round)\n",
    "    l_fix = dict(sorted(l_fix.items()))\n",
    "  if DEBUG or DBG: p('in prepare_blocked_table')\n",
    "  h = h_fix.copy()\n",
    "#  DBG = True\n",
    "#  if DBG: d(h)\n",
    "  if DEBUG and round == 0: p(l_fix)\n",
    "  for tup in l_fix.keys():\n",
    "    rows=[-1,-1]\n",
    "    cols=[-1,-1]\n",
    "    found = False\n",
    "    for i in [0, 1]:\n",
    "      node = nodes[tup[i]]\n",
    "      if h_fix.iloc[node] == 0:\n",
    "        rows[i] = node[0]\n",
    "        cols[i] = node[1]\n",
    "        found = True\n",
    "    if not found:   #  mark \"soft block\" (no node is 0)\n",
    "      for i in [0, 1]:\n",
    "        node = nodes[tup[i]]\n",
    "        rows[i] = node[0]\n",
    "        cols[i] = node[1]\n",
    "#      if DEBUG or DBG: p(tup, rows, cols, -90)\n",
    "      block = '-'\n",
    "      if rows[0] == rows[1]:\n",
    "        rows[1] += 1\n",
    "        cols[0] += 1\n",
    "      if cols[0] == cols[1]:\n",
    "        cols[1] += 1\n",
    "        rows[0] += 1\n",
    "        block = '/'\n",
    "      for r in range(rows[0], rows[1]):\n",
    "        for c in range(cols[0], cols[1]):\n",
    "          h.iloc[r, c] = block\n",
    "      continue\n",
    "    if -1 in rows or -1 in cols:\n",
    "      index = 0 if rows[0] == -1 else 1\n",
    "      index2 = 1 - index\n",
    "      node = nodes[tup[index]]\n",
    "      if rows[index2] == node[0]:   #same row\n",
    "        rows[index] = rows[index2]\n",
    "        if cols[index2] < node[1]:\n",
    "          sav = cols[index2]\n",
    "          cols[1] = node[1] - 1\n",
    "          cols[0] = sav + 1\n",
    "        else:\n",
    "          cols[index] = node[1] + 1\n",
    "        if cols[0] > cols[1]:\n",
    "          cols[0], cols[1] = cols[1], cols[0]\n",
    "      else:\n",
    "        cols[index] = cols[index2]\n",
    "        if rows[index2] < node[0]:\n",
    "          sav = rows[index2]\n",
    "          rows[1] = node[0] - 1\n",
    "          rows[0] = sav + 1\n",
    "        else:\n",
    "          rows[index] = node[0] + 1\n",
    "        if rows[0] > rows[1]:\n",
    "          rows[0], rows[1] = rows[1], rows[0]\n",
    "    for r in range(rows[0], rows[1] + 1):\n",
    "      for c in range(cols[0], cols[1] + 1):\n",
    "        h.iloc[r, c] = 'X'\n",
    "  h_fix = h.copy()\n",
    "    # now remove links that are \"hard\" blocked, or soft blocked without a link of the soft nodes\n",
    "  for city, link in links.items():\n",
    "    for lk in link:\n",
    "      tup = (city, lk)\n",
    "      blocked = is_road_blocked(h, tup, ['X'])\n",
    "      #if city == 60: p('hard blocked:', tup, blocked, city, nodes[city], lk, nodes[lk])\n",
    "      if not blocked:\n",
    "        blocked = is_road_blocked(h, tup)\n",
    "        if blocked and tup in l_fix:\n",
    "          blocked = False\n",
    "      if blocked:\n",
    "        if DEBUG or DBG: p('blocked:', tup, tup in l_fix, city, nodes[city], lk, nodes[lk], link, links[city], link == links[city])\n",
    "        link.remove(lk)\n",
    "        link_ = links[lk]\n",
    "        link_.remove(city)\n",
    "  remove_single(round=-1) # not to do also all the other checks\n",
    "#prepare_blocked_table(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-savannah",
   "metadata": {},
   "source": [
    "## Check for islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonBinTree:\n",
    "    def __init__(self, val = None):\n",
    "        self.val = val\n",
    "        self.nodes = []\n",
    "        self.list = []\n",
    "        self.non_zero ={}\n",
    "        if not val is None:\n",
    "          self.add_city(val)\n",
    "            \n",
    "    def add_city(self, city):\n",
    "      self.list.append(city)\n",
    "      h = h_fix.iloc[nodes[city]]\n",
    "      if val(h) > 0:\n",
    "        self.non_zero[city] = h\n",
    "      \n",
    "    def add_node(self, key, val):\n",
    "      def add_list(node, val):\n",
    "        for v in val:\n",
    "          if not v in node.list:\n",
    "            node.add_city(v)\n",
    "            \n",
    "      if self.val is None:\n",
    "        self.val = key\n",
    "        self.add_city(key)\n",
    "        add_list(self, val)\n",
    "        return\n",
    "      nd = self\n",
    "      n_nd = 0\n",
    "      dbg_key = []#[85, 87]\n",
    "      while True:\n",
    "        if key in dbg_key: p('start of while loop', nd.val, self.val, key, val, nd.list, key in nd.list)\n",
    "        if key in nd.list:\n",
    "          add_list(nd, val)\n",
    "          if key in dbg_key: p('start2 of while loop', nd.val, self.val, key, val, nd.list, key in nd.list)\n",
    "          \n",
    "            # verify if need to combine nodes\n",
    "          for v in val:\n",
    "            for node in nd.nodes:\n",
    "              if key in dbg_key: p('start3 of while loop', nd.val, val, v, nd.nodes, node.val, node.list, v in node.list)\n",
    "              if v in node.list:\n",
    "                if key in dbg_key: p('start4 of while loop', nd.val, val, v, nd.nodes, node.val, node.list, v in node.list)\n",
    "#                nd.add_node(node.val, node.list)\n",
    "                add_list(nd, node.list)\n",
    "                if key in dbg_key: p('start5 of while loop', nd.val, val, v, nd.nodes, node.val, node.list, v in node.list)\n",
    "                nd.nodes.remove(node)\n",
    "                if key in dbg_key: p('start6 of while loop', nd.val, val, v, nd.nodes, node.val, node.list, v in node.list)\n",
    "                del node\n",
    "                break\n",
    "          \n",
    "          if key in dbg_key: p('checking if need to combine lists due to adding val to a later list', nd.val, self.val, key, val)\n",
    "            # verify if need to combine nodes (nodes after the current node in the list)\n",
    "          if nd == self:  # this was already done above so no need to do it again\n",
    "            return True\n",
    "          idx = self.nodes.index(nd)\n",
    "          if key in dbg_key: p('check combine - pass \"self\" test', nd.val, key, val, idx, len(self.nodes))\n",
    "          for i in range(idx + 1, len(self.nodes)):\n",
    "            node = self.nodes[i]\n",
    "            if key in dbg_key: p(f'\\tsearching in val={node.val} key={key}', node.list, key in node.list)\n",
    "            found = False\n",
    "            if key in node.list:\n",
    "              found = True\n",
    "            else:\n",
    "              for v in val:\n",
    "                if v in node.list:\n",
    "                  found = True\n",
    "                  break\n",
    "            if found:\n",
    "              if DEBUG: p('found in later list so combining', node.val, node.list, nd.val, nd.list)\n",
    "#              nd.add_node(node.val, node.list)\n",
    "              add_list(nd, node.list)\n",
    "              if key in dbg_key: p(f'\\tdoing combine in val={nd.val} key={key}', nd.list, self.nodes)\n",
    "              self.nodes.remove(node)\n",
    "              del node\n",
    "              if key in dbg_key: p(f'\\tafter doing combine in val={nd.val} key={key}', nd.list, self.nodes)\n",
    "              break\n",
    "                \n",
    "          return True\n",
    "          # the key is not in the list now check the nodes in the val\n",
    "        found = False\n",
    "        for v in val:\n",
    "          if v in nd.list:\n",
    "              found = True\n",
    "              break\n",
    "        if found:\n",
    "          nd.add_city(key)\n",
    "          add_list(nd, val)\n",
    "          \n",
    "          if DEBUG: p('checking2 if need to combine lists due to adding val to a later list', nd.val, key, val, nd.list)\n",
    "          #p(self)\n",
    "          #dbg_key=[141]#, 31, 54, 135,]\n",
    "            # code moved to above - might need to duplicate it here too\n",
    "          # the key is now in the nd.list so we go back to the start of the looop and this time the test 'key in nd.list' will be true\n",
    "          continue\n",
    "#          return True\n",
    "           # none of the val is in the list so search on nodes of the master Tree only since we do not create sub nodes to the branches\n",
    "        if len(self.nodes) > 0:\n",
    "          if nd == self:\n",
    "            nd = self.nodes[n_nd]\n",
    "            continue\n",
    "          if nd.val == self.nodes[n_nd].val:\n",
    "            n_nd += 1\n",
    "            if len(self.nodes) > n_nd:\n",
    "              nd = self.nodes[n_nd]\n",
    "              continue\n",
    "        break\n",
    "      new_node = NonBinTree()\n",
    "      self.nodes.append(new_node)\n",
    "      new_node.add_node(key, val)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"(val={self.val}): list={self.list}, non_zero={self.non_zero}\\n\\tnodes = {self.nodes}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_connected_node_list():\n",
    "  l = {}\n",
    "  t = [0,0]\n",
    "  for t[0], t[1] in l_fix.keys():\n",
    "    for i in [0,1]:\n",
    "      if t[i] in l:\n",
    "        if not t[i-1] in l[t[i]]:\n",
    "          l[t[i]].append(t[1-i])\n",
    "      else:\n",
    "        l[t[i]] = [t[1-i]]\n",
    "  return l\n",
    "\n",
    "def make_tree():\n",
    "  l = make_connected_node_list()\n",
    "  l_list = list(l.keys())\n",
    "  tree = NonBinTree()\n",
    "  n = 0\n",
    "  while len(l_list) > 0:\n",
    "    city = l_list.pop(0)\n",
    "    tree.add_node(city, l[city])\n",
    "  return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_island(round=0):\n",
    "  if round == 0:\n",
    "    tree = make_tree()\n",
    "    if len(tree.nodes) == 0:  # no islands - all connected\n",
    "      return tree\n",
    "  if len(links) == 0:  # doing a 'test' and no more links -> need another test\n",
    "    return\n",
    "  n_nd = 0\n",
    "  nd = tree\n",
    "  j = -1\n",
    "  nd_special2 = []  # look for nodes with 2 non zero, each has 1 connection left, and both r in the list -> forbidden because an island\n",
    "  if DEBUG: p(tree)\n",
    "  remove_a_link = False\n",
    "  while True:\n",
    "    found = False\n",
    "    nz = nd.non_zero\n",
    "    if len(nz) > 1:\n",
    "      for j in range(n_nd, len(tree.nodes)):\n",
    "        nz = tree.nodes[j].non_zero\n",
    "        if len(nz) == 1:\n",
    "          nd = tree.nodes[j]\n",
    "          n_nd = j\n",
    "          break\n",
    "        if len(nz) == 2:\n",
    "          nd_special2.append(nz)\n",
    "      if len(nz) > 1: # passed through all nodes\n",
    "        break\n",
    "    if len(nz) == 0:\n",
    "      p(tree)\n",
    "      return\n",
    "    if DEBUG: p('in find_island 0:', nd.val, nd_special2, j, n_nd)\n",
    "    if len(nz) == 1:\n",
    "      node, n_conn = list(nz.items())[0]\n",
    "      link = links[node]\n",
    "      #p('0:', nd.val, nz, n_conn, node, link, n_nd, j, nodes[node])\n",
    "      for lk in link:\n",
    "        tup = (node, lk)\n",
    "        tup_lk = nodes[lk]\n",
    "          # if one of the nodes has 1 connection originally it means we cannot connect to it otherwise we have an island\n",
    "        if hashi.iloc[tup_lk] == 1:\n",
    "          found = True\n",
    "          #p('1:', nd.val, nz, n_conn, node, link, n_nd, j, tup_lk, hashi.iloc[tup_lk])\n",
    "        elif n_conn == 1:\n",
    "            # check if another node has n_conn=1 and can be connected to this node, and thus the 2 will make an island\n",
    "          #p('1.2:', nd.val, nz, n_conn, node, link, lk, n_nd, j, tup_lk, hashi.iloc[tup_lk])\n",
    "          for i in range(len(tree.nodes)):\n",
    "            if i == j:\n",
    "              continue\n",
    "            nz_ = tree.nodes[i].non_zero\n",
    "            if len(nz_) == 1: \n",
    "              node_, n_conn_ = list(nz_.items())[0]\n",
    "              if n_conn_ == 1 and node_ in link:\n",
    "                found = True\n",
    "                  # added 01.04.2021 (switch to correct link - was deletingthe other one)\n",
    "                  # in case lk is link[0] but node_ is link[1] or vice versa\n",
    "                lk = node_\n",
    "                tup_lk = nodes[lk]\n",
    "                #p('2:', nd.val, nz, n_conn, node, link, n_nd, j, tup_lk, hashi.iloc[tup_lk])\n",
    "                #p('1.2:', tree.nodes[i].val, node_, n_conn_, link, node_ in link)\n",
    "                break\n",
    "          if not found:\n",
    "            # check if can connect to one of the nodes in it's own chain that has left 1 connection and thus closed the loop=island\n",
    "            if DEBUG: p(tup, tup_lk, h_fix.iloc[tup_lk], link, lk, j, tree.nodes[j].val, tree.nodes[j].list)\n",
    "            if h_fix.iloc[tup_lk] == 1 and lk in tree.nodes[j].list:\n",
    "              found = true\n",
    "              break            \n",
    "        elif n_conn == 2:\n",
    "          if DEBUG: p('3:', tree.nodes[j].val, node, link, lk, tup, tup_lk, tree.nodes[j])\n",
    "            # check if one of the nodes has n_conn=2 and can be connected to this node, \n",
    "            # and thus the 2 will make an island\n",
    "          for i in range(len(tree.nodes)):\n",
    "            if i == j:\n",
    "              continue\n",
    "            nz_ = tree.nodes[i].non_zero\n",
    "            if len(nz_) == 1: \n",
    "              node_, n_conn_ = list(nz_.items())[0]\n",
    "              if n_conn_ == 2 and node_ in link:  # change on  01.04.2021 (was n_conn ==1 which does not make sense if our npde has 2)\n",
    "                found = True\n",
    "                if DEBUG: p('4:', tree.nodes[i].val, node_, n_conn_, link, node_ in link)\n",
    "                remove_a_link = True\n",
    "                break\n",
    "        if found:\n",
    "          break\n",
    "      if found:\n",
    "        break\n",
    "    n_nd += 1\n",
    "    if found or n_nd >= len(tree.nodes):\n",
    "      break\n",
    "    nd = tree.nodes[n_nd]\n",
    "  if not found and len(nd_special2) > 0:\n",
    "    for nz in nd_special2:\n",
    "      node1, n_conn1 = list(nz.items())[0]\n",
    "      node2, n_conn2 = list(nz.items())[1]\n",
    "      link = links[node1]\n",
    "      if n_conn1 == n_conn2 == 1 and node2 in link:\n",
    "        found = True\n",
    "        node = node1\n",
    "        lk = node2\n",
    "        tup_lk = nodes[node]\n",
    "        break\n",
    "  if found:\n",
    "    tup = (node, lk)\n",
    "    if DEBUG: p('found_island:', tup_lk, node, link, lk, tup, 'remove_a_link')\n",
    "    if DEBUG: p(links)\n",
    "    reason = f'island {hashi.iloc[tup_lk[0], tup_lk[1]]}'\n",
    "    if remove_a_link:\n",
    "      reason = f'island - reduce a link: {hashi.iloc[tup_lk[0], tup_lk[1]]}'\n",
    "      link = links[node]\n",
    "      lk_ = link[1] if lk == link[0] else link[0]\n",
    "      #p(node, nodes[node], lk_, link)\n",
    "      update_link(nodes[node][0], nodes[node][1], node, 1, lk_, reason)\n",
    "      link = links[lk]\n",
    "      lk_ = link[1] if node == link[0] else link[0]\n",
    "      #p(lk, nodes[lk], lk_, link)\n",
    "      update_link(nodes[lk][0], nodes[lk][1], lk, 1, lk_, reason)\n",
    "    else:\n",
    "      link.remove(lk)\n",
    "      link = links[lk]\n",
    "      link.remove(node)\n",
    "  if DEBUG:\n",
    "    p('tree: ',tree)\n",
    "    fin_cell(found, 'Not found_island')\n",
    "  return tree\n",
    "#DEBUG=False\n",
    "#find_island()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-covering",
   "metadata": {},
   "source": [
    "# Solve Hashi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_table(df):\n",
    "  return int(df[df.apply(lambda x: x.apply(lambda x: val(x) > 0))].sum().sum())\n",
    "#sum_table(hashi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "columns=['node', 'org_val', 'cur_val', '#lines', 'dir', 'new_val', 'reason']\n",
    "def solve_hashi():\n",
    "  global DEBUG, l_fix, h_fix, links, links_org, links, roads, nodes, df_sol\n",
    "  l_fix = {}\n",
    "  h_fix = hashi.copy()\n",
    "  score = sum_table(hashi)\n",
    "  p('Sum = ', score)\n",
    "  if score % 2:\n",
    "    p('Hashi table NOT EVEN', score)\n",
    "    return\n",
    "  nodes = {}\n",
    "  roads = {}\n",
    "  df_sol = pd.DataFrame(columns=columns)\n",
    "\n",
    "  make_nodes(h_fix)\n",
    "  if DEBUG: p('make links')\n",
    "  links, links_org = make_links()\n",
    "  p('Before:')\n",
    "  d(h_fix)\n",
    "\n",
    "  #DEBUG = True\n",
    "\n",
    "  prepare_blocked_table()\n",
    "  if DEBUG: p('After')\n",
    "  if DEBUG: d(h_fix)\n",
    "  new_score = sum_table(h_fix)\n",
    "  p('Sum = ', score, new_score)\n",
    "  if DEBUG:\n",
    "    p('links:', links)\n",
    "    p()\n",
    "    p(list(links.keys()))\n",
    "    p()\n",
    "    p(l_fix)\n",
    "\n",
    "  new_score = 0\n",
    "  #DEBUG = True\n",
    "  if DEBUG: d(h_fix)\n",
    "  test_list = []\n",
    "  while new_score != score and score > 0:  \n",
    "    while new_score != score and score > 0:  \n",
    "      new_score = score\n",
    "      prepare_blocked_table(1)\n",
    "      score = sum_table(h_fix)\n",
    "      p('Sum = ', score, new_score)\n",
    "      #DEBUG = True\n",
    "    #DEBUG = True\n",
    "    find_island()\n",
    "    remove_single(round=-1)  # just in case find_island created a single\n",
    "    #DEBUG = True\n",
    "    prepare_blocked_table(1)\n",
    "    score = sum_table(h_fix)\n",
    "    if DEBUG: p()\n",
    "    p('Sum2 = ', score)\n",
    "    #DEBUG = True\n",
    "    \n",
    "    if len(test_list) == 0 and new_score == score and score > 0:\n",
    "      test_list = getPos(h_fix, [1])\n",
    "      test_i = test_j = 0\n",
    "      sav_h = deepcopy(h_fix)\n",
    "      sav_l = deepcopy(l_fix)\n",
    "      sav_links = deepcopy(links)\n",
    "      #test_j = 1\n",
    "      if DEBUG: p('init tests')\n",
    "      if DEBUG: d(h_fix)\n",
    "      if DEBUG: p(links)\n",
    "    if len(test_list) > 0 and new_score == score and score > 0:\n",
    "      if test_i > 0 or test_j > 0:\n",
    "        h_fix = deepcopy(sav_h)\n",
    "        l_fix = deepcopy(sav_l)\n",
    "        links = deepcopy(sav_links)\n",
    "        if DEBUG: p('restore tests')\n",
    "\n",
    "      if DEBUG: d(h_fix)\n",
    "      if DEBUG: p(links)\n",
    "      if DEBUG: p(test_list)\n",
    "      \n",
    "      tup = test_list[test_i]\n",
    "      node = nodes[tup]\n",
    "      if test_j == len(links[node]):\n",
    "        test_j = 0\n",
    "        test_i += 1\n",
    "        tup = test_list[test_i]\n",
    "        node = nodes[tup]\n",
    "      link = links[node]\n",
    "      lk = link[test_j]\n",
    "      test_j += 1\n",
    "      p('\\ntrying a solution for a node of 1:', tup, node, test_i, test_j, lk, link)\n",
    "      #DEBUG = True\n",
    "      update_link(tup[0], tup[1], node, 1, lk, 'test')\n",
    "      if DEBUG: d(h_fix)\n",
    "      new_score = 0\n",
    "\n",
    "  tree = make_tree()\n",
    "  if score == 0:\n",
    "    if len(tree.nodes) == 0:  # verify all connected\n",
    "      #d(df_sol)\n",
    "      #disp_to_file(df_sol, f_name + '_solution.png')\n",
    "      #plot_trip(trip())\n",
    "      p('Done - ALL CONNECTED')\n",
    "    else:\n",
    "      p()\n",
    "      p('NOT ALL CONNECTED')\n",
    "      p()\n",
    "      p(tree)\n",
    "    #plot_trip(trip())\n",
    "  else:\n",
    "    d(h_fix)\n",
    "    p()\n",
    "    p(tree)\n",
    "    \n",
    "solve_hashi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-logistics",
   "metadata": {},
   "source": [
    "# Check Hashi (not completed (in case not solved before plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sav_h = h_fix.copy()\n",
    "#  sav_l = l_fix.copy()\n",
    "#  sav_links = links.copy()\n",
    "  \n",
    "#  solution = trip()\n",
    "#  tree = make_tree()\n",
    "#  nz = tree.non_zero\n",
    "#df_sol.iloc[28:56,]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
